{
  
    
        "post0": {
            "title": "Exploring Digital Literacy and Privacy Protection with Data Visualization Using Python",
            "content": "Install dependencies and import the libraries . !pip3 install researchpy pyreadstat joypy plot_likert . Requirement already satisfied: researchpy in ./.venv/lib/python3.10/site-packages (0.3.2) Requirement already satisfied: pyreadstat in ./.venv/lib/python3.10/site-packages (1.1.4) Requirement already satisfied: joypy in ./.venv/lib/python3.10/site-packages (0.2.6) Requirement already satisfied: plot_likert in ./.venv/lib/python3.10/site-packages (0.3.7.1) Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from researchpy) (1.7.3) Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from researchpy) (1.3.5) Requirement already satisfied: patsy in ./.venv/lib/python3.10/site-packages (from researchpy) (0.5.2) Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from researchpy) (1.21.5) Requirement already satisfied: statsmodels in ./.venv/lib/python3.10/site-packages (from researchpy) (0.13.1) Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (from joypy) (3.5.1) Requirement already satisfied: pytz&gt;=2017.3 in ./.venv/lib/python3.10/site-packages (from pandas-&gt;researchpy) (2021.3) Requirement already satisfied: python-dateutil&gt;=2.7.3 in ./.venv/lib/python3.10/site-packages (from pandas-&gt;researchpy) (2.8.2) Requirement already satisfied: six&gt;=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;researchpy) (1.16.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib-&gt;joypy) (1.3.2) Requirement already satisfied: cycler&gt;=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib-&gt;joypy) (0.11.0) Requirement already satisfied: pillow&gt;=6.2.0 in ./.venv/lib/python3.10/site-packages (from matplotlib-&gt;joypy) (8.4.0) Requirement already satisfied: fonttools&gt;=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib-&gt;joypy) (4.28.5) Requirement already satisfied: packaging&gt;=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib-&gt;joypy) (21.3) Requirement already satisfied: pyparsing&gt;=2.2.1 in ./.venv/lib/python3.10/site-packages (from matplotlib-&gt;joypy) (3.0.6) WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available. You should consider upgrading via the &#39;/home/devajji/Desktop/code/projects/d590-project/.venv/bin/python -m pip install --upgrade pip&#39; command. . import pandas as pd import numpy as np import matplotlib.pyplot as plt plt.rc(&#39;font&#39;, family=&#39;Open Sans&#39;) import seaborn as sns custom_params = {&quot;axes.spines.right&quot;: False, &quot;axes.spines.top&quot;: False} sns.set_theme(style=&quot;ticks&quot;, rc=custom_params) import textwrap from decimal import Decimal import researchpy as rp import statsmodels.api as sm import plot_likert import typing from scipy import stats from joypy import joyplot from collections import defaultdict from statsmodels.formula.api import ols from statsmodels.graphics.mosaicplot import mosaic from statsmodels.graphics.factorplots import interaction_plot . Import dataset . dataset = pd.read_spss(&#39;./ATP-W49.sav&#39;) . dataset.head(2) . QKEY DEVICE_TYPE_W49 LANG_W49 FORM_W49 SOCMEDIAUSEa_W49 SOCMEDIAUSEb_W49 SOCMEDIAUSEc_W49 SOCMEDIAUSEd_W49 SNSUSER_W49 ELECTFTGSNSINT_W49 ... F_PARTY_FINAL F_PARTYLN_FINAL F_PARTYSUM_FINAL F_INCOME F_INCOME_RECODE F_REG F_IDEO F_ACSWEB F_VOLSUM WEIGHT_W49 . 0 100260.0 | Tablet | English | Form 2 | No, do not use this | No, do not use this | No, do not use this | No, do not use this | Does not use social media | NaN | ... | Republican | NaN | Rep/Lean Rep | $50,000 to less than $75,000 | $30-$74,999 | You are ABSOLUTELY CERTAIN that you are regist... | Very conservative | Accesses Internet by paying a cell phone compa... | No | 0.308756 | . 1 100588.0 | Mobile phone | English | Form 1 | Yes, use this | Yes, use this | Yes, use this | No, do not use this | Social media user | I am worn out by how many political posts and ... | ... | Democrat | NaN | Dem/Lean Dem | $50,000 to less than $75,000 | $30-$74,999 | You are ABSOLUTELY CERTAIN that you are regist... | Moderate | Accesses Internet by paying a cell phone compa... | No | 0.417927 | . 2 rows × 143 columns . The dataset has 143 columns out of which, the following are the columns of intereset for our analysis and visualization project : . Demographic variables : . F_SEX - sex of the respondant | F_METRO - region of the respondant | F_EDUCCAT - education level of the respondant | F_INCOME_RECODE - family annual income bracket | Digital literacy measure variables : . UNDERSTANDCO - understanding what companies are doing with the data they collect | UNDERSTANDGOV - understanding what the government is doing with the data it collects | PP4 - understanding the privacy policies they read online | KNOW1-KNOW10 - general questions about the technology field | TOTALKNOW - only numerical variable that records how many questions from KNOW1-KNOW10 did each respondant answer correctly. | Control and concern about personal data protection variables : . CONTROLCO - how much control do the respondants feel they have over the data collected by companies about them | CONTROLGOV - how much control do the respondants feel they have over the data collected by the government about them | CONCERNCO - how concerned participants are about how companies are using the data they collect on them | CONCERNGOV - how concerned participants are about how government is using the data they collect on them | How much of what participants did online as well as offline are being tracked by the government and advertisers, technology firms, or other companies : . TRACKCO1a | TRACKCO1b | TRACKGOV1a | TRACKGOV1b | Pre-processing . Removing redundant string from column headers _W49 . dataset.columns = dataset.columns.str.replace(&#39;_W49&#39;, &#39;&#39;) . Exploratory Data Analysis of Demographics . Education level . def change_width(ax, new_value) : for patch in ax.patches : current_width = patch.get_width() diff = current_width - new_value # we change the bar width patch.set_width(new_value) # we recenter the bar patch.set_x(patch.get_x() + diff * .5) ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) . fig = plt.subplots(figsize=(10, 6)) total = sum(dataset.F_EDUCCAT.value_counts().to_dict().values()) ax = sns.countplot( data=dataset, x=&#39;F_EDUCCAT&#39;, order=[&#39;College graduate+&#39;, &#39;Some College&#39;, &#39;H.S. graduate or less&#39;, &quot;Don&#39;t know/Refused&quot;], palette=[&#39;red&#39;, &#39;grey&#39;, &#39;grey&#39;, &#39;grey&#39;], dodge=False ) change_width(ax, 0.5) plt.xlabel(&#39;Education level&#39;) for p in ax.patches: percentage = &#39;{:.1f}%&#39;.format(100 * p.get_height()/total) x = p.get_x() + p.get_width() - 0.1 y = p.get_height() + 15 ax.annotate(percentage, (x, y),ha=&#39;right&#39;) plt.show() . fig = plt.figure(figsize=(7.5, 5)) boxplot_tn_educcat = dataset[[&#39;TOTALKNOW&#39;, &#39;F_EDUCCAT&#39;]] ax = sns.violinplot( data=boxplot_tn_educcat, x=&#39;F_EDUCCAT&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;, order=[&#39;College graduate+&#39;, &#39;Some College&#39;, &#39;H.S. graduate or less&#39;, &quot;Don&#39;t know/Refused&quot;], ); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . group1 = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_EDUCCAT&#39;] == &#39;College graduate+&#39;] group2 = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_EDUCCAT&#39;] == &#39;H.S. graduate or less&#39;] t_test = stats.ttest_ind(group1, group2) print(f&#39;t: {t_test.statistic:.3f}, p: {t_test.pvalue:.3f}&#39;) model = ols(&#39;TOTALKNOW ~ F_EDUCCAT&#39;, data=dataset).fit() sm.stats.anova_lm(model, typ=2) . t: 28.277, p: 0.000 . sum_sq df F PR(&gt;F) . F_EDUCCAT 4480.659108 | 3.0 | 263.578887 | 6.134541e-157 | . Residual 24184.351191 | 4268.0 | NaN | NaN | . Gender . fig = plt.subplots(figsize=(4, 4)) total = sum(dataset.F_SEX.value_counts().to_dict().values()) ax = sns.countplot( data=dataset, x=&#39;F_SEX&#39;, palette=[&#39;red&#39;, &#39;grey&#39;] ) change_width(ax, 0.5) for p in ax.patches: percentage = &#39;{:.1f}%&#39;.format(150 * p.get_height()/total) x = p.get_x() + p.get_width() - 0.05 y = p.get_height() + 40 ax.annotate(percentage, (x, y),ha=&#39;right&#39;) plt.xlabel(&#39;Sex&#39;); . fig = plt.figure(figsize=(4, 4)) boxplot_tn_sex = dataset[[&#39;TOTALKNOW&#39;, &#39;F_SEX&#39;]] ax = sns.violinplot(data=boxplot_tn_sex, x=&#39;F_SEX&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() boxplot_tn_metro = dataset[[&#39;TOTALKNOW&#39;, &#39;F_SEX&#39;]] plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . male = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_SEX&#39;] == &#39;Male&#39;] female = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_SEX&#39;] == &#39;Female&#39;] t_test = stats.ttest_ind(male, female) print(f&#39;t: {t_test.statistic:.3f}, p: {t_test.pvalue:.3f}&#39;) model = ols(&#39;TOTALKNOW ~ F_SEX&#39;, data=dataset).fit() sm.stats.anova_lm(model, typ=2) . t: 15.929, p: 0.000 . sum_sq df F PR(&gt;F) . F_SEX 1607.815155 | 1.0 | 253.735492 | 1.540099e-55 | . Residual 27057.195145 | 4270.0 | NaN | NaN | . Region . import matplotlib matplotlib.rcParams[&#39;font.size&#39;] = 12 matplotlib.rcParams[&#39;text.color&#39;] = &#39;black&#39; plt.pie( dataset.F_METRO.value_counts(), labels=[&#39;Metropolitan&#39;, &#39;Non-metropolitan&#39;], colors=[&#39;grey&#39;, &#39;red&#39;], autopct = &quot;%0.2f%%&quot;, ); . fig = plt.figure(figsize=(4, 4)) boxplot_tn_metro = dataset[[&#39;TOTALKNOW&#39;, &#39;F_METRO&#39;]] ax = sns.violinplot(data=boxplot_tn_metro, x=&#39;F_METRO&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . group1 = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_METRO&#39;] == &#39;Metropolitan&#39;] group2 = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_METRO&#39;] == &#39;Non-metropolitan&#39;] t_test = stats.ttest_ind(group1, group2) print(f&#39;t: {t_test.statistic:.3f}, p: {t_test.pvalue:.3f}&#39;) model = ols(&#39;TOTALKNOW ~ F_METRO&#39;, data=dataset).fit() sm.stats.anova_lm(model, typ=2) . t: 6.517, p: 0.000 . sum_sq df F PR(&gt;F) . F_METRO 282.315845 | 1.0 | 42.472664 | 7.999713e-11 | . Residual 28382.694455 | 4270.0 | NaN | NaN | . Annual Income . fig = plt.subplots(figsize=(10, 6)) ax = sns.countplot( data=dataset, x=&#39;F_INCOME_RECODE&#39;, order=[&#39;$75,000+&#39;, &#39;$30-$74,999&#39;, &#39;&lt;$30,000&#39;, &quot;Don&#39;t know/Refused&quot;], palette=[&#39;red&#39;, &#39;grey&#39;, &#39;grey&#39;, &#39;grey&#39;] ) plt.xlabel(&#39;Family Annual Income&#39;) change_width(ax, 0.5) for p in ax.patches: percentage = &#39;{:.1f}%&#39;.format(100 * p.get_height()/total) x = p.get_x() + p.get_width() - 0.13 y = p.get_height() + 15 ax.annotate(percentage, (x, y),ha=&#39;right&#39;) plt.show() . fig = plt.figure(figsize=(7, 4)) boxplot_tn_metro = dataset[[&#39;TOTALKNOW&#39;, &#39;F_INCOME_RECODE&#39;]] ax = sns.violinplot( data=boxplot_tn_metro, x=&#39;F_INCOME_RECODE&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;, order=[&#39;$75,000+&#39;, &#39;$30-$74,999&#39;, &#39;&lt;$30,000&#39;, &quot;Don&#39;t know/Refused&quot;] ); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . group1 = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_INCOME_RECODE&#39;] == &#39;$30-$74,999&#39;] group2 = dataset[&#39;TOTALKNOW&#39;][dataset[&#39;F_INCOME_RECODE&#39;] == &#39;$75,000+&#39;] t_test = stats.ttest_ind(group1, group2) print(f&#39;t: {t_test.statistic:.3f}, p: {t_test.pvalue:.3f}&#39;) model = ols(&#39;TOTALKNOW ~ F_INCOME_RECODE&#39;, data=dataset).fit() sm.stats.anova_lm(model, typ=2) . t: -12.185, p: 0.000 . sum_sq df F PR(&gt;F) . F_INCOME_RECODE 2882.482205 | 3.0 | 159.053889 | 9.964902e-98 | . Residual 25782.528095 | 4268.0 | NaN | NaN | . . Visualizing Categorical Data . Likert-plots . def show_values(axs, orient=&quot;h&quot;, space=.1, custom_labels=True): def _single(ax): axes = ax.patches[1:] if custom_labels: axes = ax.patches[1:len(ax.patches) - 1] for p in axes: _x = p.get_x() + p.get_width() + float(space) _y = p.get_y() + p.get_height() - (p.get_height() * 0.5) value = &#39;{:.1f}&#39;.format(p.get_width()) ax.text(_x, _y, value, ha=&quot;left&quot;) if isinstance(axs, np.ndarray): for idx, ax in np.ndenumerate(axs): _single(ax) else: _single(axs) . def plot_likert_graph(series, scale, xlabel, ylabel, no_legend=False, custom_labels=False): Colors = typing.List[str] TRANSPARENT = &quot;#ffffff00&quot; colors: Colors = [ TRANSPARENT, &quot;firebrick&quot;, &quot;lightcoral&quot;, &quot;#E9D66B&quot;, &quot;cornflowerblue&quot;, &quot;darkblue&quot;, ] ax = plot_likert.plot_likert(series, scale, plot_percentage=True, colors=colors) ax.figure.set_size_inches(8, 2) ax.xaxis.set_label_text(xlabel) ax.set_yticklabels([ylabel]) # show_values(ax, custom_labels=custom_labels) for p in ax.patches[1:]: left, bottom, width, height = p.get_bbox().bounds if custom_labels: ax.annotate(f&#39;{width:.1f}&#39;, xy=(left + width/2, bottom + height + 0.05), ha=&#39;center&#39;, va=&#39;center&#39;) else: ax.annotate(f&#39;{width:.2f}&#39;, xy=(left+width/2, bottom + height + 0.05), ha=&#39;center&#39;, va=&#39;center&#39;) if no_legend: ax.get_legend().remove() plt.box(False) . UNDERSTAND Variables . scale = [ &#39;A great deal&#39;, &#39;Some&#39;, &#39;Very little&#39;, &#39;Nothing&#39;, ] xlabel = &#39;How much do you feel you understand what companies are doing with the data they collect about you?&#39; plot_likert_graph(pd.DataFrame( dataset.UNDERSTANDCO[dataset.UNDERSTANDCO != &#39;Refused&#39;]), scale, xlabel, ylabel=None) xlabel = &#39;How much do you feel you understand what the government is doing with the data they collect about you?&#39; plot_likert_graph(pd.DataFrame( dataset.UNDERSTANDGOV[dataset.UNDERSTANDGOV != &#39;Refused&#39;]), scale, xlabel, ylabel=None, no_legend=True ) . CONCERN Variables . concernco_no_nan = dataset.CONCERNCO.dropna() concernco_no_nan = concernco_no_nan[concernco_no_nan != &#39;Refused&#39;] concerngov_no_nan = dataset.CONCERNGOV.dropna() concerngov_no_nan = concerngov_no_nan[concerngov_no_nan != &#39;Refused&#39;] . scale = [ &#39;Very concerned&#39;, &#39;Somewhat concerned&#39;, &#39;Not too concerned&#39;, &#39;Not at all concerned&#39;, ] xlabel = &#39;How concerned are you, if at all, about how companies are using the data they collect about you?&#39; plot_likert_graph(pd.DataFrame(concernco_no_nan), scale, xlabel, ylabel=None) xlabel = &#39;How concerned are you, if at all, about how the government is using the data it collects about you?&#39; plot_likert_graph(pd.DataFrame(concerngov_no_nan), scale, xlabel, ylabel=None, no_legend=True) . fig = plt.figure(figsize=(8, 4)) boxplot_tn_metro = pd.concat([dataset.TOTALKNOW, dataset.CONCERNGOV.dropna().cat.remove_categories(&quot;Refused&quot;)], axis=1) ax = sns.violinplot( data=boxplot_tn_metro, x=&#39;CONCERNGOV&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;, order=[&quot;Very concerned&quot;, &quot;Somewhat concerned&quot;, &quot;Not too concerned&quot;, &quot;Not at all concerned&quot;] ); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.title(&#39;CONCERGOV&#39;) plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . fig = plt.figure(figsize=(7.5, 4)) boxplot_tn_metro = pd.concat([dataset.TOTALKNOW, dataset.CONCERNCO.dropna().cat.remove_categories(&quot;Refused&quot;)], axis=1) ax = sns.violinplot( data=boxplot_tn_metro, x=&#39;CONCERNCO&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;, order=[&quot;Very concerned&quot;, &quot;Somewhat concerned&quot;, &quot;Not too concerned&quot;, &quot;Not at all concerned&quot;] ); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.title(&#39;CONCERCO&#39;) plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . CONTROL variables . controlco_no_nan = dataset.CONTROLCO.dropna() controlco_no_nan = controlco_no_nan[controlco_no_nan != &#39;Refused&#39;] controlgov_no_nan = dataset.CONTROLGOV.dropna() controlgov_no_nan = controlgov_no_nan[controlgov_no_nan != &#39;Refused&#39;] . scale = [ &#39;No control&#39;, &#39;Very little control&#39;, &#39;Some control&#39;, &#39;A great deal of control&#39;, ] xlabel = &#39;How much control do you think you have over the data that companies collect about you?&#39; plot_likert_graph(pd.DataFrame(controlco_no_nan), scale, xlabel, ylabel=None) xlabel = &#39;How much control do you think you have over the data the government collects about you?&#39; plot_likert_graph(pd.DataFrame(controlgov_no_nan), scale, xlabel, ylabel=None, no_legend=True, custom_labels=True) . fig = plt.figure(figsize=(7, 4)) boxplot_tn_metro = pd.concat([dataset.TOTALKNOW, dataset.CONTROLCO.dropna().cat.remove_categories(&quot;Refused&quot;)], axis=1) ax = sns.violinplot( data=boxplot_tn_metro, x=&#39;CONTROLCO&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm_r&quot;, order=[&quot;A great deal of control&quot;, &quot;Some control&quot;, &quot;Very little control&quot;, &quot;No control&quot;] ); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.title(&#39;CONTROLCO&#39;) plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . fig = plt.figure(figsize=(7, 4)) boxplot_tn_metro = pd.concat([dataset.TOTALKNOW, dataset.CONTROLGOV.dropna().cat.remove_categories(&quot;Refused&quot;)], axis=1) ax = sns.violinplot( data=boxplot_tn_metro, x=&#39;CONTROLGOV&#39;, y=&#39;TOTALKNOW&#39;, palette=&quot;coolwarm&quot;, order=[&quot;A great deal of control&quot;, &quot;Some control&quot;, &quot;Very little control&quot;, &quot;No control&quot;] ); ax.spines[&#39;top&#39;].set_visible(False) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;left&#39;].set_visible(False) ax.spines[&#39;bottom&#39;].set_color(&#39;#DDDDDD&#39;) ax.tick_params(bottom=False, left=False) ax.set_axisbelow(True) ax.yaxis.grid(True, color=&#39;#EEEEEE&#39;) ax.xaxis.grid(False) fig.tight_layout() plt.title(&#39;CONTROLGOV&#39;) plt.xlabel(&quot;&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . Testing the effectiveness of the scatter plot . fig, ax = plt.subplots(figsize=(12, 8)) no_nan_controlgov = dataset.dropna(subset=[&#39;CONTROLGOV&#39;]) boxplot_tn_metro = pd.concat([no_nan_controlgov.TOTALKNOW, no_nan_controlgov.CONTROLGOV.cat.remove_categories(&quot;Refused&quot;)], axis=1) sns.swarmplot( data=boxplot_tn_metro, x=&#39;CONTROLGOV&#39;, y=&#39;TOTALKNOW&#39;, s = 4, ax=ax, palette=&quot;viridis&quot;, order=[&quot;A great deal of control&quot;, &quot;Some control&quot;, &quot;Very little control&quot;, &quot;No control&quot;] ); plt.title(&#39;CONTROLGOV&#39;) plt.xlabel(&quot;Control Levels&quot;) plt.ylabel(&quot;Total number of knowledge questions nanswered correctly (maximum 10)&quot;); . /home/devajji/Desktop/code/projects/d590-project/.venv/lib/python3.10/site-packages/seaborn/categorical.py:1296: UserWarning: 64.8% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot. warnings.warn(msg, UserWarning) /home/devajji/Desktop/code/projects/d590-project/.venv/lib/python3.10/site-packages/seaborn/categorical.py:1296: UserWarning: 64.4% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot. warnings.warn(msg, UserWarning) . PP4 variables . fig = plt.subplots(figsize=(10, 6)) ax = sns.countplot( data=pd.DataFrame(dataset.PP4.dropna().cat.remove_categories(&quot;Refused&quot;)), x=&#39;PP4&#39;, order=[&quot;A great deal&quot;, &quot;Some&quot;, &quot;Very little&quot;, &quot;Not at all&quot;], palette=[&quot;grey&quot;, &quot;red&quot;, &quot;grey&quot;, &quot;grey&quot;] ) plt.xlabel(&#39;How much do you typically understand the privacy policies you read?&#39;) change_width(ax, 0.5) for p in ax.patches: percentage = &#39;{:.1f}%&#39;.format(100 * p.get_height()/total) x = p.get_x() + p.get_width() - 0.1 y = p.get_height() + 15 ax.annotate(percentage, (x, y),ha=&#39;right&#39;) plt.show() . Vertical Grouped Bar plots to visualize the TRACK variables . def bar_plot(ax, data, group_stretch=0.05, bar_stretch=0.95, legend=True, x_labels=True, label_fontsize=8, colors=None, barlabel_offset=1, bar_labeler=lambda k, i, s: str(round(s, 3))): sorted_data = list(sorted(data.items(), key=lambda elt: elt[1], reverse=True)) sorted_k, sorted_v = zip(*sorted_data) max_n_bars = max(len(v) for v in data.values()) group_centers = np.cumsum([max_n_bars for _ in sorted_data]) - (max_n_bars / 2) bar_offset = (1 - bar_stretch) / 2 bars = defaultdict(list) if colors is None: colors = {g_name: [f&quot;C{i}&quot; for _ in values] for i, (g_name, values) in enumerate(data.items())} # for g_i, ((g_name, vals), g_center) in enumerate(zip(sorted_data, group_centers)): n_bars = len(vals) group_beg = g_center - (n_bars / 2) + (bar_stretch / 2) + group_stretch for val_i, val in enumerate(vals): bar = ax.bar(group_beg + val_i + bar_offset, height=val, width= group_stretch / bar_stretch, color=colors[g_name][val_i])[0] bars[g_name].append(bar) if bar_labeler is not None: x_pos = bar.get_x() + (bar.get_width() / 2.0) y_pos = val + barlabel_offset barlbl = bar_labeler(g_name, val_i, val) ax.text(x_pos, y_pos, barlbl, ha=&quot;center&quot;, va=&quot;bottom&quot;, fontsize=label_fontsize) if legend: bars = defaultdict(list) n_bars = len(vals) group_beg = g_center - (n_bars / 2) + (bar_stretch / 2) bar = ax.bar(group_beg + 0 + bar_offset, height=0, width=bar_stretch, color=&#39;C0&#39;)[0] bars[&#39;TRACKCO1a&#39;].append(bar) bar = ax.bar(group_beg + 1 + bar_offset, height=0, width=bar_stretch, color=&#39;C1&#39;)[0] bars[&#39;TRACKCO1b&#39;].append(bar) bar = ax.bar(group_beg + 2 + bar_offset, height=0, width=bar_stretch, color=&#39;C2&#39;)[0] bars[&#39;TRACKGOV1a&#39;].append(bar) bar = ax.bar(group_beg + 3 + bar_offset, height=0, width=bar_stretch, color=&#39;C3&#39;)[0] bars[&#39;TRACKGOV1b&#39;].append(bar) ax.legend( [bars[k][0] for k in [&#39;TRACKCO1a&#39;, &#39;TRACKCO1b&#39;, &#39;TRACKGOV1a&#39;, &#39;TRACKGOV1b&#39;]], [&#39;TRACKCO1a&#39;, &#39;TRACKCO1b&#39;, &#39;TRACKGOV1a&#39;, &#39;TRACKGOV1b&#39;], bbox_to_anchor=(1,1), loc=&quot;upper left&quot; ) ax.set_xticks(group_centers) if x_labels: ax.set_xticklabels(sorted_k, rotation=0) else: ax.set_xticklabels() return bars, group_centers . Creating the required dataframe without the &quot;Refused&quot; category. . track_df = dataset[[&#39;TRACKCO1a&#39;, &#39;TRACKCO1b&#39;, &#39;TRACKGOV1a&#39;, &#39;TRACKGOV1b&#39;]] bar_graph = { &#39;All or almost all of it&#39;: [], &#39;Most of it&#39;: [], &#39;Some of it&#39;: [], &#39;Very little of it&#39;: [], &#39;None of it&#39;: [], } for col in track_df.columns: value_counts = track_df[col].value_counts().to_dict() for key, value in value_counts.items(): if key == &#39;Refused&#39;: continue bar_graph[key].append(value) bar_graph . {&#39;All or almost all of it&#39;: [881, 237, 475, 207], &#39;Most of it&#39;: [703, 413, 489, 255], &#39;Some of it&#39;: [381, 842, 671, 703], &#39;Very little of it&#39;: [88, 422, 317, 604], &#39;None of it&#39;: [76, 214, 163, 351]} . Defining the colours of the bars . colors = {&#39;All or almost all of it&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;], &#39;Most of it&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;], &#39;Some of it&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;], &#39;Very little of it&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;], &#39;None of it&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;],} . fig, ax = plt.subplots(figsize=(12, 8)) bar_plot(ax, bar_graph, group_stretch=0.8, bar_stretch=0.95, legend=True, colors=colors, x_labels=True, label_fontsize=8, barlabel_offset=0.05, bar_labeler=lambda k, i, s: str(round(s, 3))); . The above grouped bar chart is a little hard to understand, we can&#39;t really saw which bar belongs to which group . def show_values_custom_track(axs, orient=&quot;h&quot;, space=.1): def _single(ax): for p in axs.patches: _x = p.get_x() + p.get_width() _y = p.get_y() + p.get_height() - (p.get_height() * 0.01) value = &#39;{:.2f}&#39;.format(100 * p.get_width()) ax.text(_x, _y, value, ha=&quot;left&quot;) if isinstance(axs, np.ndarray): for idx, ax in np.ndenumerate(axs): _single(ax) else: _single(axs) . track_df = dataset[[&#39;TRACKCO1a&#39;, &#39;TRACKCO1b&#39;, &#39;TRACKGOV1a&#39;, &#39;TRACKGOV1b&#39;]] answers = {} for track in track_df.columns: value_counts = track_df[track].value_counts(normalize=True).to_dict() del value_counts[&#39;Refused&#39;] answers[track] = value_counts track_answers_df = pd.DataFrame(data=answers) track_answers_df_t = track_answers_df.T track_answers_df_t . All or almost all of it Most of it Some of it Very little of it None of it . TRACKCO1a 0.411682 | 0.328505 | 0.178037 | 0.041121 | 0.035514 | . TRACKCO1b 0.110748 | 0.192991 | 0.393458 | 0.197196 | 0.100000 | . TRACKGOV1a 0.222795 | 0.229362 | 0.314728 | 0.148687 | 0.076454 | . TRACKGOV1b 0.097092 | 0.119606 | 0.329737 | 0.283302 | 0.164634 | . fig, ax = plt.subplots(figsize=(13, 4)) ax = track_answers_df_t[::-1].plot( kind=&#39;barh&#39;, ax = ax, stacked=True, title=&#39;Distribution of answers for TRACK questions&#39;, color={ &quot;All or almost all of it&quot;: &quot;firebrick&quot;, &quot;Most of it&quot;: &quot;lightcoral&quot;, &quot;Some of it&quot;: &quot;#E9D66B&quot;, &quot;Very little of it&quot;: &quot;cornflowerblue&quot;, &quot;None of it&quot;: &quot;lightblue&quot;} ) for p in ax.patches: left, bottom, width, height = p.get_bbox().bounds ax.annotate(f&#39;{width * 100:.2f}&#39;, xy=(left+width/2, bottom + height + 0.1), ha=&#39;center&#39;, va=&#39;center&#39;) ax.xaxis.set_ticks([0, 0.20, 0.40, 0.60, 0.80, 1]) ax.xaxis.set_ticklabels([0, 20, 40, 60, 80, 100]) plt.legend(bbox_to_anchor=(1,1), loc=&quot;upper left&quot;); plt.box(False) . The above horizontal stacked bar chart with percentage labels on top of the bars and semantically encoded colours makes it easier to understand the distribution of the answers. . Importing the csv which has the KNOW answers encoded into ordinal . dataset_know_ordinal = pd.read_csv(&#39;./dataset_knowall.csv&#39;) . ans_cols = [col for col in dataset_know_ordinal if col.endswith(&#39;_ans&#39;)] labels = [col[:-4] for col in dataset_know_ordinal if col.endswith(&#39;_ans&#39;)] correct_ans = {} for ans_col in ans_cols: value_counts = dataset_know_ordinal[ans_col].value_counts(sort=True).to_dict() refuse = value_counts[-2.0] del value_counts[-2.0] value_counts[&#39;Refused&#39;] = refuse incorrect = value_counts[0] del value_counts[0] value_counts[&#39;Incorrect&#39;] = incorrect n_sure = value_counts[-1] del value_counts[-1] value_counts[&#39;Not Sure&#39;] = n_sure correct = value_counts[1.0] del value_counts[1.0] value_counts[&#39;Correct&#39;] = correct correct_ans[ans_col[:-4]] = correct plt.title(f&#39;Distribution of Answers for the knowledge questions&#39;) plt.scatter(x=value_counts.keys(), y=list(value_counts.values())) plt.legend(labels, bbox_to_anchor=(1,1), loc=&quot;upper left&quot;); . Scatter plot to visualize the KNOW variables is not so helpful in this way. . ans_cols = [col for col in dataset_know_ordinal if col.endswith(&#39;_ans&#39;)] answers = {} for ans_col in ans_cols: value_counts = dataset_know_ordinal[ans_col].value_counts(sort=True, normalize=True).to_dict() print(value_counts) refuse = value_counts[-2.0] del value_counts[-2.0] # value_counts[&#39;Refused&#39;] = refuse incorrect = value_counts[0] del value_counts[0] value_counts[&#39;Incorrect&#39;] = incorrect n_sure = value_counts[-1] del value_counts[-1] value_counts[&#39;Not Sure&#39;] = n_sure correct = value_counts[1.0] del value_counts[1.0] value_counts[&#39;Correct&#39;] = correct answers[ans_col[:-4]] = value_counts . {1: 0.6441947565543071, -1: 0.25397940074906367, 0: 0.08941947565543071, -2: 0.012406367041198503} {1: 0.6090823970037453, -1: 0.3017322097378277, 0: 0.0800561797752809, -2: 0.009129213483146067} {1: 0.4934456928838951, -1: 0.25397940074906367, 0: 0.24110486891385768, -2: 0.01147003745318352} {-1: 0.5252808988764045, 1: 0.31273408239700373, 0: 0.14723782771535582, -2: 0.014747191011235955} {1: 0.6828183520599251, 0: 0.175561797752809, -1: 0.13951310861423222, -2: 0.002106741573033708} {-1: 0.5049157303370787, 1: 0.27902621722846443, 0: 0.21090823970037453, -2: 0.005149812734082397} {1: 0.462312734082397, -1: 0.413623595505618, 0: 0.11282771535580524, -2: 0.011235955056179775} {-1: 0.5093632958801498, 0: 0.2565543071161049, 1: 0.22542134831460675, -2: 0.008661048689138577} {0: 0.5573501872659176, 1: 0.27130149812734083, -1: 0.16760299625468164, -2: 0.003745318352059925} {-1: 0.7808988764044944, 1: 0.15215355805243447, 0: 0.0625, -2: 0.004447565543071161} . answers_df = pd.DataFrame(data=answers) answers_df_t = answers_df.T answers_df_t = answers_df_t.sort_values(by=[&#39;Correct&#39;]) answers_df_t = answers_df_t.iloc[ answers_df_t.index.str.extract( &#39;( d+)&#39;, expand=False ).astype(int).argsort() ] answers_df_t . Incorrect Not Sure Correct . KNOW1 0.089419 | 0.253979 | 0.644195 | . KNOW2 0.080056 | 0.301732 | 0.609082 | . KNOW3 0.241105 | 0.253979 | 0.493446 | . KNOW4 0.147238 | 0.525281 | 0.312734 | . KNOW5 0.175562 | 0.139513 | 0.682818 | . KNOW6 0.210908 | 0.504916 | 0.279026 | . KNOW7 0.112828 | 0.413624 | 0.462313 | . KNOW8 0.256554 | 0.509363 | 0.225421 | . KNOW9 0.557350 | 0.167603 | 0.271301 | . KNOW10 0.062500 | 0.780899 | 0.152154 | . fig, ax = plt.subplots(figsize=(12, 6)) ax = answers_df_t[::-1].plot( ax=ax, kind=&#39;barh&#39;, stacked=True, title=&#39;Distribution of answers for Knowledge questions&#39;, color={&quot;Refused&quot;: &quot;grey&quot;, &quot;Incorrect&quot;: &quot;#b22222&quot;, &quot;Not Sure&quot;: &quot;#f7b71d&quot;, &quot;Correct&quot;: &quot;#80c161&quot;} ) for p in ax.patches: left, bottom, width, height = p.get_bbox().bounds ax.annotate(f&#39;{width * 100:.1f}&#39;, xy=(left + width/2, bottom + height + 0.15), ha=&#39;center&#39;, va=&#39;center&#39;) ax.xaxis.set_ticks([0, 0.20, 0.40, 0.60, 0.80, 1]) ax.xaxis.set_ticklabels([0, 20, 40, 60, 80, 100]) plt.legend(bbox_to_anchor=(1,1), loc=&quot;upper left&quot;); . The above stacked bar graphs is again, much more easier to understand . Testing the effectiveness of joyplots which have the density estimates. . qa_df = dataset_know_ordinal[[col for col in dataset_know_ordinal if col.endswith(&#39;_ans&#39;)]].stack().reset_index().drop(&#39;level_0&#39;, axis=1).rename({&#39;level_1&#39;: &#39;question&#39;, 0: &#39;answer&#39;}, axis=1) result_col = &#39;answer_string&#39; qa_df[result_col] = &#39;&#39; qa_df[result_col] = np.select( condlist=[ qa_df[&#39;answer&#39;] == -2, qa_df[&#39;answer&#39;] == -1, qa_df[&#39;answer&#39;] == 0, qa_df[&#39;answer&#39;] == 1, ], choicelist=[&#39;Refused&#39;, &#39;Not Sure&#39;, &#39;Incorrect&#39;, &#39;Correct&#39;], default=&#39;Not Sure&#39; ) qa_df.head() . question answer answer_string . 0 KNOW1_ans | -1 | Not Sure | . 1 KNOW2_ans | -1 | Not Sure | . 2 KNOW3_ans | -1 | Not Sure | . 3 KNOW4_ans | -1 | Not Sure | . 4 KNOW5_ans | 1 | Correct | . ax = joyplot( data=qa_df[[&#39;question&#39;, &#39;answer&#39;]], by=&#39;question&#39;, legend=True, figsize=(12, 8) ); . The above histograms are good, but we cannot get an exact idea of how good it is. . Histograms of the TOTALKNOW variable . h = list(dataset.TOTALKNOW) h.sort() hmean = np.mean(h) hstd = np.std(h) pdf = stats.norm.pdf(h, hmean, hstd) fig, ax = plt.subplots(1, 1, figsize=(10, 8)) ax.hist(h, density=True, color=&#39;#7995c4&#39;); plt.plot(h, pdf, color=&#39;r&#39;, lw=2.5) plt.axvline(x=dataset.TOTALKNOW.mean(), c=&#39;r&#39;, lw=1.5) ax.annotate(f&#39;mean = {dataset.TOTALKNOW.mean():.2f}&#39;, xy=(8.2, 0.14), ha=&#39;left&#39;, va=&#39;center&#39;, bbox={&#39;boxstyle&#39;: &#39;round&#39;, &#39;fc&#39;: &#39;powderblue&#39;, &#39;ec&#39;: &#39;navy&#39;}) ax.set_frame_on(False) ax.axes.get_yaxis().set_visible(False) plt.xlabel(&#39;Total number of knowledge questions answered correctly (max of 10)&#39;) plt.show() . g = sns.displot( dataset.TOTALKNOW, height=6, aspect=1.4, bins=10, kde=True, color=&#39;#b55a67&#39;, line_kws={&#39;lw&#39;: 2.5}, facecolor=&#39;#7995c4&#39;, ) def specs(x, **kwargs): plt.axvline(x.mean(), c=&#39;r&#39;, ls=&#39;-&#39;, lw=2.5) g.map(plt.axvline, x=dataset.TOTALKNOW.mean(), c=&#39;r&#39;, lw=2.5) g.ax.annotate(f&#39;mean = {dataset.TOTALKNOW.mean():.2f}&#39;, xy=(8.1, 500.9), ha=&#39;left&#39;, va=&#39;center&#39;, bbox={&#39;boxstyle&#39;: &#39;round&#39;, &#39;fc&#39;: &#39;powderblue&#39;, &#39;ec&#39;: &#39;navy&#39;}) plt.xlabel(&#39;Total number of knowledge questions answered correctly (max of 10)&#39;) plt.ylabel(&#39;Frequency&#39;); . kwargs = {&#39;cumulative&#39;: True} g = sns.ecdfplot( dataset.TOTALKNOW, ); plt.axvline(np.mean(dataset.TOTALKNOW), color=&#39;red&#39;) plt.xlabel(&#39;Total number of knowledge questions answered correctly (max of 10)&#39;) plt.ylabel(&#39;Frequency&#39;); . Converting the categorical variables to ordinal variables in order to perform statistical tests . mapper = { &#39;Refused&#39;: 0, &#39;No control&#39;: 1, &#39;Very little control&#39;: 2, &#39;Some control&#39;: 3, &#39;A great deal of control&#39;: 4 } # df_test = dataset[[col for col in dataset if col.startswith(&#39;KNOW&#39;)]] df_test = dataset[[&#39;CONTROLCO&#39;, &#39;CONTROLGOV&#39;, &#39;CONCERNCO&#39;, &#39;CONCERNGOV&#39;, &#39;TOTALKNOW&#39;]] . for col in [col for col in dataset if col.startswith(&#39;KNOW&#39;)]: res_col = col + &#39;_ordinal&#39; ordvar = df_test.CONTROLCO.replace(mapper) df_test[&#39;CONTROLCO_convt&#39;] = ordvar df_test.CONTROLCO_convt.value_counts() . /tmp/ipykernel_18748/1497339069.py:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy df_test[&#39;CONTROLCO_convt&#39;] = ordvar . 2.0 1134 1.0 621 3.0 313 4.0 68 0.0 4 Name: CONTROLCO_convt, dtype: int64 . rp.summary_cont(df_test.TOTALKNOW.groupby(df_test.CONTROLCO)) . . N Mean SD SE 95% Conf. Interval . CONTROLCO . A great deal of control 68 | 3.7206 | 2.5617 | 0.3107 | 3.1005 | 4.3407 | . No control 621 | 3.7198 | 2.5065 | 0.1006 | 3.5223 | 3.9173 | . Refused 4 | 1.0000 | 1.4142 | 0.7071 | -1.2503 | 3.2503 | . Some control 313 | 3.8850 | 2.6311 | 0.1487 | 3.5924 | 4.1776 | . Very little control 1134 | 4.3598 | 2.5803 | 0.0766 | 4.2095 | 4.5101 | . rp.summary_cont(df_test.TOTALKNOW.groupby(df_test.CONTROLGOV)) . . N Mean SD SE 95% Conf. Interval . CONTROLGOV . A great deal of control 65 | 3.2615 | 2.8133 | 0.3490 | 2.5644 | 3.9587 | . No control 908 | 4.1542 | 2.5536 | 0.0847 | 3.9879 | 4.3205 | . Refused 7 | 1.2857 | 1.8898 | 0.7143 | -0.4621 | 3.0335 | . Some control 229 | 3.9345 | 2.7546 | 0.1820 | 3.5758 | 4.2932 | . Very little control 923 | 4.3694 | 2.5610 | 0.0843 | 4.2040 | 4.5349 | . model = ols(&#39;TOTALKNOW ~ CONTROLCO&#39;, data=df_test).fit() sm.stats.anova_lm(model, typ=2) . sum_sq df F PR(&gt;F) . CONTROLCO 227.964430 | 4.0 | 8.663912 | 6.187958e-07 | . Residual 14044.003327 | 2135.0 | NaN | NaN | . model = ols(&#39;TOTALKNOW ~ CONTROLGOV&#39;, data=df_test).fit() sm.stats.anova_lm(model, typ=2) . sum_sq df F PR(&gt;F) . CONTROLGOV 160.895461 | 4.0 | 6.016848 | 0.000082 | . Residual 14219.432400 | 2127.0 | NaN | NaN | . df_test . CONTROLCO CONTROLGOV CONCERNCO CONCERNGOV TOTALKNOW CONTROLCO_convt . 0 NaN | No control | NaN | Not too concerned | 1.0 | NaN | . 1 Some control | NaN | Somewhat concerned | NaN | 4.0 | 3.0 | . 2 Very little control | NaN | Not too concerned | NaN | 5.0 | 2.0 | . 3 NaN | No control | NaN | Not at all concerned | 0.0 | NaN | . 4 No control | NaN | Very concerned | NaN | 4.0 | 1.0 | . ... ... | ... | ... | ... | ... | ... | . 4267 NaN | Very little control | NaN | Somewhat concerned | 3.0 | NaN | . 4268 NaN | No control | NaN | Somewhat concerned | 2.0 | NaN | . 4269 NaN | No control | NaN | Not too concerned | 7.0 | NaN | . 4270 NaN | Very little control | NaN | Somewhat concerned | 8.0 | NaN | . 4271 NaN | No control | NaN | Very concerned | 8.0 | NaN | . 4272 rows × 6 columns . model = ols(&#39;TOTALKNOW ~ CONCERNCO&#39;, data=df_test).fit() sm.stats.anova_lm(model, typ=2) . sum_sq df F PR(&gt;F) . CONCERNCO 229.725885 | 4.0 | 8.731953 | 5.451980e-07 | . Residual 14042.241872 | 2135.0 | NaN | NaN | . model = ols(&#39;TOTALKNOW ~ CONCERNGOV&#39;, data=df_test).fit() sm.stats.anova_lm(model, typ=2) . sum_sq df F PR(&gt;F) . CONCERNGOV 282.831141 | 4.0 | 10.668239 | 1.466194e-08 | . Residual 14097.496720 | 2127.0 | NaN | NaN | . no_nan_controlco = dataset[dataset[&#39;CONTROLCO&#39;].notna()][&#39;CONTROLCO&#39;] no_nan_controlgov = dataset[dataset[&#39;CONTROLGOV&#39;].notna()][&#39;CONTROLGOV&#39;] no_nan_totalknow = dataset[dataset[&#39;CONTROLGOV&#39;].notna()][&#39;TOTALKNOW&#39;] no_nan_controlco.shape, no_nan_controlgov.shape, no_nan_totalknow.shape . ((2140,), (2132,), (2132,)) . df = pd.DataFrame(dataset[[&#39;PP4&#39;, &#39;UNDERSTANDCO&#39;, &#39;UNDERSTANDGOV&#39;, &#39;TOTALKNOW&#39;]]) frame ={ &#39;PP4&#39;: pd.factorize(df[&#39;PP4&#39;])[0], &#39;UNDERSTANDCO&#39;: pd.factorize(df[&#39;UNDERSTANDCO&#39;])[0], &#39;UNDERSTANDGOV&#39;: pd.factorize(df[&#39;UNDERSTANDGOV&#39;])[0], &#39;TOTALKNOW&#39;: pd.factorize(df[&#39;TOTALKNOW&#39;])[0] } df = pd.DataFrame(frame) . cols = [&#39;PP4&#39;, &#39;UNDERSTANDCO&#39;, &#39;UNDERSTANDGOV&#39;, &#39;TOTALKNOW&#39;] p = pd.DataFrame([ [stats.pearsonr(df[c], df[y])[1] for y in cols] for c in cols], columns=df.columns, index=df.columns ).copy() p[&quot;type&quot;] = &quot;pearsonr&quot; p.index.name=&quot;col&quot; p = p.set_index([p.index,&quot;type&quot;]) c = df.corr() c[&quot;type&quot;] = &quot;correlation&quot; c.index.name = &quot;col&quot; c = c.set_index([c.index,&quot;type&quot;]) df = c.combine_first(p) df . . The below cells are the experiments we have performed. . Install Dependencies . import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import textwrap from scipy.stats import pearsonr from statsmodels.graphics.mosaicplot import mosaic . Filtering rows based on nan values in the columns CONTROLGRPx . I split it into two dataframes as the rows where CONTROLGRPabc are non-nan, there the CONTROLGRPdef are nan and vice-versa . no_nan_controlgrp_abc = dataset[dataset[&#39;CONTROLGRPa&#39;].notna()] no_nan_controlgrp_def = dataset[dataset[&#39;CONTROLGRPd&#39;].notna()] len(no_nan_controlgrp_abc), len(no_nan_controlgrp_def) . Trying to understand the correlation between the two nominal attributes TOTALKNOW and CONTROLGRPa by encoding the CONTROLGRPa responses into numbers. . df_test = no_nan_controlgrp_def[[&#39;TOTALKNOW&#39;, &#39;CONTROLGRPa&#39;, &#39;CONTROLGRPb&#39;, &#39;CONTROLGRPc&#39;]] . mapper = {&#39;Refused&#39;:0, &#39;Offline: does not have internet&#39;:0, &#39;No control&#39;: 1, &#39;A little control&#39;: 2, &#39;A lot of control&#39;: 3} ordvar = no_nan_controlgrp_def.CONTROLGRPe.replace(mapper) df_test.CONTROLGRPd = ordvar ordvar = no_nan_controlgrp_def.CONTROLGRPd.replace(mapper) df_test.CONTROLGRPe = ordvar ordvar = no_nan_controlgrp_def.CONTROLGRPf.replace(mapper) df_test.CONTROLGRPf = ordvar . print(pearsonr(df_test.TOTALKNOW, df_test.CONTROLGRPe)) print(pearsonr(df_test.TOTALKNOW, df_test.CONTROLGRPd)) print(pearsonr(df_test.TOTALKNOW, df_test.CONTROLGRPf)) . no_nan_controlgrp_abc.KNOW2 = no_nan_controlgrp_abc.KNOW2.apply(lambda k : &quot; n&quot;.join(textwrap.wrap(k,10))) . list(no_nan_controlgrp_abc.KNOW2.unique()) . long_strings = list(no_nan_controlgrp_abc.KNOW2.unique()) break_string = lambda k : &quot; n&quot;.join(textwrap.wrap(k,10)) for k in long_strings: break_string(k) . fig, ax = plt.subplots(figsize=(12, 4)) plt.rcParams[&#39;font.size&#39;] = 10.0 labels = lambda _: &#39;&#39; mosaic(no_nan_controlgrp_abc, [&#39;KNOW2&#39;, &#39;CONTROLGRPa&#39;], gap=0.1, ax=ax, labelizer=labels); . def category_scatter_plot(df,colx,coly,cols,color=[&#39;grey&#39;,&#39;black&#39;],ratio=10,font=&#39;Helvetica&#39;,save=False,save_name=&#39;Default&#39;): &#39;&#39;&#39; Goal: This function create an scatter plot for categorical variables. It&#39;s useful to compare two lists with elements in common. Input: - df: required. pandas DataFrame with at least two columns with categorical variables you want to relate, and the value of both (if it&#39;s just an adjacent matrix write 1) - colx: required. The name of the column to display horizontaly - coly: required. The name of the column to display vertically - cols: required. The name of the column with the value between the two variables - color: optional. Colors to display in the visualization, the length can be two or three. The two first are the colors for the lines in the matrix, the last one the font color and markers color. default [&#39;grey&#39;,&#39;black&#39;] - ratio: optional. A ratio for controlling the relative size of the markers. default 10 - font: optional. The font for the ticks on the matrix. default &#39;Helvetica&#39; - save: optional. True for saving as an image in the same path as the code. default False - save_name: optional. The name used for saving the image (then the code ads .png) default: &quot;Default&quot; Output: No output. Matplotlib object is not shown by default to be able to add more changes. &#39;&#39;&#39; # Create a dict to encode the categeories into numbers (sorted) colx_codes=dict(zip(df[colx].sort_values().unique(),range(len(df[colx].unique())))) coly_codes=dict(zip(df[coly].sort_values(ascending=False).unique(),range(len(df[coly].unique())))) # Apply the encoding df[colx]=df[colx].apply(lambda x: colx_codes[x]) df[coly]=df[coly].apply(lambda x: coly_codes[x]) # Prepare the aspect of the plot plt.rcParams[&#39;xtick.bottom&#39;] = plt.rcParams[&#39;xtick.labelbottom&#39;] = False plt.rcParams[&#39;xtick.top&#39;] = plt.rcParams[&#39;xtick.labeltop&#39;] = True plt.rcParams[&#39;font.sans-serif&#39;]=font plt.rcParams[&#39;xtick.color&#39;]=color[-1] plt.rcParams[&#39;ytick.color&#39;]=color[-1] plt.box(False) # Plot all the lines for the background for num in range(len(coly_codes)): plt.hlines(num,-1,len(colx_codes)+1,linestyle=&#39;dashed&#39;,linewidth=1,color=color[num%2],alpha=0.5) for num in range(len(colx_codes)): plt.vlines(num,-1,len(coly_codes)+1,linestyle=&#39;dashed&#39;,linewidth=1,color=color[num%2],alpha=0.5) # Plot the scatter plot with the numbers plt.scatter(df[colx], df[coly], s=df[cols]*ratio, zorder=2, color=color[-1]) # Change the ticks numbers to categories and limit them plt.xticks(ticks=list(colx_codes.values()),labels=colx_codes.keys(),rotation=90) plt.yticks(ticks=list(coly_codes.values()),labels=coly_codes.keys()) plt.xlim(xmin=-1,xmax=len(colx_codes)) plt.ylim(ymin=-1,ymax=len(coly_codes)) . no_nan_controlgrp_abc = dataset[dataset[&#39;CONTROLGRPa&#39;].notna()] ct = pd.crosstab(no_nan_controlgrp_abc[&#39;KNOW2&#39;], no_nan_controlgrp_abc[&#39;CONTROLGRPa&#39;]) ct . The above table is visualised in the below graph . category_scatter_plot(no_nan_controlgrp_abc, &#39;KNOW2&#39;, &#39;CONTROLGRPa&#39;, &#39;TOTALKNOW&#39;) . sns.catplot(x=&quot;TOTALKNOW&quot;, y=&quot;CONTROLCO&quot;, data=no_nan_controlgrp_abc) . corr = dataset.apply(lambda x : pd.factorize(x)[0]).corr(method=&#39;pearson&#39;, min_periods=1) corr . from traitlets.config.manager import BaseJSONConfigManager from pathlib import Path path = Path.home() / &quot;.jupyter&quot; / &quot;nbconfig&quot; cm = BaseJSONConfigManager(config_dir=str(path)) tmp = cm.update( &quot;rise&quot;, { &quot;theme&quot;: &quot;serif&quot;, &quot;transition&quot;: &quot;fade&quot;, &quot;start_slideshow_at&quot;: &quot;selected&quot;, &quot;autolaunch&quot;: False, &quot;autoSlide&quot;: 15000, &quot;width&quot;: &quot;100%&quot;, &quot;height&quot;: &quot;100%&quot;, &quot;header&quot;: &quot;&quot;, &quot;footer&quot;:&quot;&quot;, &quot;scroll&quot;: True, &quot;enable_chalkboard&quot;: True, &quot;slideNumber&quot;: True, &quot;center&quot;: False, &quot;controlsLayout&quot;: &quot;edges&quot;, &quot;slideNumber&quot;: True, &quot;hash&quot;: True, } ) .",
            "url": "https://rahul0598.github.io/digital-literacy-tu-devajji/2021/01/10/digital-literacy-tu-devajji.html",
            "relUrl": "/2021/01/10/digital-literacy-tu-devajji.html",
            "date": " • Jan 10, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rahul0598.github.io/digital-literacy-tu-devajji/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rahul0598.github.io/digital-literacy-tu-devajji/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}